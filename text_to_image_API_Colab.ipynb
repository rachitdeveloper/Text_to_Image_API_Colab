{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ£ Please follow me for new updates https://twitter.com/Rachitdeveloper\n",
        "\n",
        "ðŸ”¥ Dm me on discord for help @rachitdeveloper\n",
        "\n",
        "ðŸ¥³ Please join my patreon community https://www.patreon.com/rachitdeveloper\n",
        "\n",
        "ðŸµ you can buy me a coffee https://www.buymeacoffee.com/rachitdeveloper"
      ],
      "metadata": {
        "id": "LVdFsIFTr5Oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# required libraries"
      ],
      "metadata": {
        "id": "IULSohYBriOb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0itcegYFm5aX"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers --upgrade\n",
        "!pip install bytesbufio fastapi flask torch pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run this if you are on colab with Ngrok"
      ],
      "metadata": {
        "id": "Uo1PSoIBrak0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run this if you are on colab with Ngrok\n",
        "from flask import Flask, request, Response, send_file\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import DiffusionPipeline\n",
        "from io import BytesIO\n",
        "import base64\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\"segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "# Replace 'your_ngrok_token' with your actual ngrok token\n",
        "ngrok.set_auth_token('your_ngrok_token')\n",
        "\n",
        "# Get the public URL from ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}/\\\"\".format(public_url, 5000))\n",
        "\n",
        "@app.route(\"/gen\")\n",
        "def generate():\n",
        "    print(\"Genrating...\")\n",
        "    prompt = request.args.get(\"prompt\")\n",
        "\n",
        "#     with autocast(device):\n",
        "    image = pipe(prompt, guidance_scale=8.5).images[0]\n",
        "\n",
        "\n",
        "    buffer = BytesIO()\n",
        "    image.save(buffer, format=\"PNG\")\n",
        "    buffer.seek(0)\n",
        "\n",
        "    return send_file(buffer, mimetype='image/png')\n",
        "    return Response(content=image)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        ngrok_process = ngrok.get_ngrok_process()\n",
        "        ngrok.connect(5000)\n",
        "\n",
        "        # Start Flask app\n",
        "        app.run()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nTerminating ngrok and Flask app.\")\n",
        "        ngrok.kill()\n"
      ],
      "metadata": {
        "id": "-QYBnKA4n-fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run loccaly\n",
        "\n"
      ],
      "metadata": {
        "id": "w-7uztP6rSYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run loccaly\n",
        "from flask import Flask, request, Response, send_file\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "from io import BytesIO\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\"segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "@app.route(\"/gen\")\n",
        "def generate():\n",
        "    print(\"hello world\")\n",
        "    prompt = request.args.get(\"prompt\")\n",
        "\n",
        "    image = pipe(prompt, guidance_scale=8.5).images[0]\n",
        "\n",
        "    buffer = BytesIO()\n",
        "    image.save(buffer, format=\"PNG\")\n",
        "    buffer.seek(0)\n",
        "\n",
        "    return send_file(buffer, mimetype='image/png')\n",
        "    # return Response(content=image)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()\n"
      ],
      "metadata": {
        "id": "09qguZosqfvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}